@article{world2015TB,
	title={Global tuberculosis report 2015},
	author={{World Health Organisation}},
	publisher={World Health Organization}
}

@article{Lackey:10356751520150601,
	Abstract = {Background: Although tuberculosis (TB) is usually curable with antibiotics, poor adherence to medication can lead to increased transmission, drug resistance, and death. Prior research has shown several factors to be associated with poor adherence, but this problem remains a substantial barrier to global TB control. We studied patients in a high-incidence district of Lima, Peru to identify factors associated with premature termination of treatment (treatment default). Methods: We conducted a prospective cohort study of adult smear-positive TB patients enrolled between January 2010 and December 2011 with no history of TB disease. Descriptive statistics and multivariable logistic regression analyses were performed to determine risk factors associated with treatment default. Results: Of the 1233 patients studied, 127 (10%) defaulted from treatment. Patients who defaulted were more likely to have used illegal drugs (OR = 4.78, 95% CI: 3.05-7.49), have multidrug-resistant TB (OR = 3.04, },
	Author = {Lackey, Brian and Seas, Carlos and Van der Stuyft, Patrick and Otero, Larissa},
	ISSN = {19326203},
	Journal = {PLoS ONE},
	Keywords = {TUBERCULOSIS -- Treatment, DISEASE incidence, MULTIDRUG resistance, PUBLIC health, PERU, LIMA (Peru), Research Article},
	Number = {6},
	Pages = {1-11},
	Title = {Patient Characteristics Associated with Tuberculosis Treatment Default: A Cohort Study in a High-Incidence Area of Lima, Peru.},
	Volume = {10},
	URL = {http://search.ebscohost.com/login.aspx?direct=true&db=aph&AN=103567515&site=ehost-live},
	Year = {2015},
}

@article{muture:6660173120110101,
	Abstract = {The article offers information on a study conducted by the authors on factors related to treatment default in tuberculosis patients in Nairobi, Kenya. The study included 945 defaulters and others who completed the treatment between 2006-2008. It states that they attributed default to ignorance, traveling away from treatment facility and feeling better. Other independent factors included alcohol abuse, low income, use of herbal medication and male gender.},
	ISSN = {14712458},
	Author={Muture, Bernard and Keraka, Margaret N and Kimuu, Peter K and Kabiru, Ephantus W and Ombeka, Victor O and Oguya, Francis},
	Journal = {BMC Public Health},
	Keywords = {TUBERCULOSIS -- Treatment, ALCOHOLISM, HERBAL medicine, NAIROBI (Kenya), KENYA},
	Number = {1},
	Pages = {696-105},
	Title = {Factors associated with default from treatment among tuberculosis patients in nairobi province, Kenya: A case control study.},
	Volume = {11},
	URL = {http://search.ebscohost.com/login.aspx?direct=true&db=aph&AN=66601731&site=ehost-live},
	month={September},
	Year = {2011},
}

@ARTICLE{Jha:10.1371/journal.pone.0008873,
	author = {Jha, Ugra Mohan AND Satyanarayana, Srinath AND Dewan, Puneet K. AND Chadha, Sarabjit AND Wares, Fraser AND Sahu, Suvanand AND Gupta, Devesh AND Chauhan, L. S.},
	journal = {PLoS ONE},
	publisher = {Public Library of Science},
	title = {Risk Factors for Treatment Default among Re-Treatment Tuberculosis Patients in India, 2006},
	year = {2010},
	month = {January},
	volume = {5},
	url = {http://dx.doi.org/10.1371%2Fjournal.pone.0008873},
	pages = {1-7},
	abstract = {<sec>
	<title>Setting</title>
	<p>Under India's Revised National Tuberculosis Control Programme (RNTCP), &gt;15% of previously-treated patients in the reported 2006 patient cohort defaulted from anti-tuberculosis treatment.</p>
	</sec><sec>
	<title>Objective</title>
	<p>To assess the timing, characteristics, and risk factors for default amongst re-treatment TB patients.</p>
	</sec><sec>
	<title>Methodology</title>
	<p>For this case-control study, in 90 randomly-selected programme units treatment records were abstracted from all 2006 defaulters from the RNTCP re-treatment regimen (cases), with one consecutively-selected non-defaulter per case. Patients who interrupted anti-tuberculosis treatment for &gt;2 months were classified as defaulters.</p>
	</sec><sec>
	<title>Results</title>
	<p>1,141 defaulters and 1,189 non-defaulters were included. The median duration of treatment prior to default was 81 days (25%?75% interquartile range 44?117 days) and documented retrieval efforts after treatment interruption were inadequate. Defaulters were more likely to have been male (adjusted odds ratio [aOR] 1.4, 95% confidence interval [CI] 1.2?1.7), have previously defaulted anti-tuberculosis treatment (aOR 1.3 95%CI 1.1?1.6], have previous treatment from non-RNTCP providers (AOR 1.3, 95%CI 1.0?1.6], or have public health facility-based treatment observation (aOR 1.3, 95%CI 1.1?1.6).</p>
	</sec><sec>
	<title>Conclusions</title>
	<p>Amongst the large number of re-treatment patients in India, default occurs early and often. Improved pre-treatment counseling and community-based treatment provision may reduce default rates. Efforts to retrieve treatment interrupters prior to default require strengthening.</p>
	</sec>},
	number = {1},
	doi = {10.1371/journal.pone.0008873}
}

@article {jittimanee:10.1111/j.1440-172X.2007.00650.x,
	author = {Jittimanee, Sirinapha X and Madigan, Elizabeth A and Jittimanee, Suksont and Nontasood, Chonkanok},
	title = {Treatment default among urban tuberculosis patients, Thailand},
	journal = {International Journal of Nursing Practice},
	volume = {13},
	number = {6},
	publisher = {Blackwell Publishing Asia},
	issn = {1440-172X},
	url = {http://dx.doi.org/10.1111/j.1440-172X.2007.00650.x},
	doi = {10.1111/j.1440-172X.2007.00650.x},
	pages = {354--362},
	keywords = {default, Donabedian, process, Thailand, tuberculosis, urban},
	year = {2007},
}

@article{chan:2003prevalence,
	title={Prevalence and predictors of default from tuberculosis treatment in Hong Kong},
	author={Chan-Yeung, M and Noertjojo, K and Leung, CC and Chan, SL and Tam, CM},
	journal={Hong Kong Medical Journal},
	volume={9},
	number={4},
	pages={263-270},
	year={2003},
	publisher={CHURCHILL LIVINGSTONE ASIA PACIFIC}
}

@article{cherkaoui:19326203,
	Abstract = {Setting: Public tuberculosis (TB) clinics in urban Morocco. Objective: Explore risk factors for TB treatment default and develop a prediction tool. Assess consequences of default, specifically risk for transmission or development of drug resistance. Design: Case-control study comparing patients who defaulted from TB treatment and patients who completed it using quantitative methods and open-ended questions. Results were interpreted in light of health professionals’ perspectives from a parallel study. A predictive model and simple tool to identify patients at high risk of default were developed. Sputum from cases with pulmonary TB was collected for smear and drug susceptibility testing. Results: 91 cases and 186 controls enrolled. Independent risk factors for default included current smoking, retreatment, work interference with adherence, daily directly observed therapy, side effects, quick symptom resolution, and not knowing one’s treatment duration. Age >50 years, never smoking, and },
	Author = {Cherkaoui, Imad and Sabouni, Radia and Ghali, Iraqi and Kizub, Darya and Billioux, Alexander C. and Bennani, Kenza and Bourkadi, Jamal Eddine and Benmamoun, Abderrahmane and Lahlou, Ouafae and Aouad, Rajae El and Dooley, Kelly E.},
	ISSN = {19326203},
	Journal = {PLoS ONE},
	Keywords = {TUBERCULOSIS patients, TUBERCULOSIS -- Treatment, THERAPEUTICS -- Complications, DRUG resistance, TUBERCULOSIS, QUANTITATIVE research, TREATMENT duration (Medical care), MEDICAL personnel, TRANSMISSION, MOROCCO, Bacterial diseases, Behavioral and social aspects of health, Global health, Health care, Health care policy, Health risk analysis, Health systems strengthening, Infectious disease control, Infectious diseases, Medicine and health sciences, Public and occupational health, Research Article, Socioeconomic aspects of health, Tropical diseases, Tuberculosis},
	Number = {4},
	Pages = {1-9},
	Title = {Treatment Default amongst Patients with Tuberculosis in Urban Morocco: Predicting and Explaining Default and Post-Default Sputum Smear and Drug Susceptibility Results.},
	Volume = {9},
	URL = {http://search.ebscohost.com/login.aspx?direct=true&db=aph&AN=95818218&site=ehost-live},
	month={April},
	Year = {2014},
}

@article{Shargie:10.1371/journal.pmed.0040037,
	author = {Shargie, Estifanos Biru AND Lindtjorn, Bernt},
	journal = {PLoS Med},
	publisher = {Public Library of Science},
	title = {Determinants of Treatment Adherence Among Smear-Positive Pulmonary
	Tuberculosis Patients in Southern Ethiopia},
	year = {2007},
	month = {February},
	volume = {4},
	url = {http://dx.doi.org/10.1371%2Fjournal.pmed.0040037},
	pages = {1-8},
	abstract = {
	<p>A prospective cohort study of smear-positive tuberculosis patients at an Ethiopian
	hospital found treatment default rates to be high; the main factors relate to physical
	access to the treatment centre.</p>
	},
	number = {2},
	doi = {10.1371/journal.pmed.0040037}
}

@article{Luo20097562,
	title = "Prediction model building with clustering-launched classification and support vector machines in credit scoring",
	journal = "Expert Systems with Applications",
	volume = "36",
	number = "4",
	pages = "7562-7566",
	year = "2009",
	note = "",
	issn = "0957-4174",
	doi = "http://dx.doi.org/10.1016/j.eswa.2008.09.028",
	url = "http://www.sciencedirect.com/science/article/pii/S0957417408006829",
	author = "Shu-Ting Luo and Bor-Wen Cheng and Chun-Hung Hsieh",
	keywords = "Credit scoring",
	keywords = "Support vector machine",
	keywords = "Clustering-launched classification ",
	abstract = "Abstract Recently, credit scoring has become a very important task as credit cards are now widely used by customers. A method that can accurately predict credit scoring is greatly needed and good prediction techniques can help to predict credit more accurately. One powerful classifier, the support vector machine (SVM), was successfully applied to a wide range of domains. In recent years, researchers have applied the SVM-based in the prediction of credit scoring, and the results have been shown it to be effective. In this study, two real world credit datasets in the University of California Irvine Machine Learning Repository were selected. \{SVM\} and a new classifier, clustering-launched classification (CLC), were employed to predict the accuracy of credit scoring. The advantages of using \{CLC\} are that it can classify data efficiently and only need one parameter needs to be decided. In substance, the results show that \{CLC\} is better than SVM. Therefore, \{CLC\} is an effective tool to predict credit scoring. "
}

@article{Danenas20153194,
	title = "Selection of Support Vector Machines based classifiers for credit risk domain",
	journal = "Expert Systems with Applications",
	volume = "42",
	number = "6",
	pages = "3194-3204",
	year = "2015",
	note = "",
	issn = "0957-4174",
	doi = "http://dx.doi.org/10.1016/j.eswa.2014.12.001",
	url = "http://www.sciencedirect.com/science/article/pii/S0957417414007660",
	author = "Paulius Danenas and Gintautas Garsva",
	keywords = "Support Vector Machines",
	keywords = "SVM",
	keywords = "Particle swarm optimization",
	keywords = "Credit risk",
	keywords = "Default assessment",
	keywords = "Classification ",
	abstract = "Abstract This paper describes an approach for credit risk evaluation based on linear Support Vector Machines classifiers, combined with external evaluation and sliding window testing, with focus on application on larger datasets. It presents a technique for optimal linear \{SVM\} classifier selection based on particle swarm optimization technique, providing significant amount of focus on imbalanced learning issue. It is compared to other classifiers in terms of accuracy and identification of each class. Experimental classification performance results, obtained using real world financial dataset from \{SEC\} \{EDGAR\} database, lead to conclusion that proposed technique is capable to produce results, comparable to other classifiers, such as logistic regression and \{RBF\} network, and thus be can be an appealing option for future development of real credit risk evaluation models. "
}

@article{hsu2003practical,
	title={A practical guide to support vector classification},
	author={Hsu, Chih-Wei and Chang, Chih-Chung and Lin, Chih-Jen and others},
	journal={Department of Computer Science, National Taiwan University}
	year={2003}
}

@Inbook{Wang2003,
	author="Wang, Sun-Chong",
	chapter="Artificial Neural Network",
	title="Interdisciplinary Computing in Java Programming",
	year="2003",
	publisher="Springer US",
	address="Boston, MA",
	pages="81-100",
	isbn="978-1-4615-0377-4",
	doi="10.1007/978-1-4615-0377-4_5",
	url="http://dx.doi.org/10.1007/978-1-4615-0377-4_5"
}

@article{Hornik1991251,
	title = "Approximation capabilities of multilayer feedforward networks",
	journal = "Neural Networks",
	volume = "4",
	number = "2",
	pages = "251-257",
	year = "1991",
	note = "",
	issn = "0893-6080",
	doi = "http://dx.doi.org/10.1016/0893-6080(91)90009-T",
	url = "http://www.sciencedirect.com/science/article/pii/089360809190009T",
	author = "Kurt Hornik",
	keywords = "Multilayer feedforward networks",
	keywords = "Activation function",
	keywords = "Universal approximation capabilities",
	keywords = "Input environment measure",
	keywords = "Lp(Î¼) approximation",
	keywords = "Uniform approximation",
	keywords = "Sobolev spaces",
	keywords = "Smooth approximation ",
	abstract = "We show that standard multilayer feedforward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to Lp(Î¼) performance criteria, for arbitrary finite input environment measures Î¼, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a function and its derivatives. "
}

@article{Huang2006489,
	title = "Extreme learning machine: Theory and applications ",
	journal = "Neurocomputing ",
	volume = "70",
	number = "1–3",
	pages = "489 - 501",
	year = "2006",
	note = "Neural NetworksSelected Papers from the 7th Brazilian Symposium on Neural Networks (SBRN '04)7th Brazilian Symposium on Neural Networks ",
	issn = "0925-2312",
	doi = "http://dx.doi.org/10.1016/j.neucom.2005.12.126",
	url = "http://www.sciencedirect.com/science/article/pii/S0925231206000385",
	author = "Guang-Bin Huang and Qin-Yu Zhu and Chee-Kheong Siew",
	keywords = "Feedforward neural networks",
	keywords = "Back-propagation algorithm",
	keywords = "Extreme learning machine",
	keywords = "Support vector machine",
	keywords = "Real-time learning",
	keywords = "Random node ",
	abstract = "It is clear that the learning speed of feedforward neural networks is in general far slower than required and it has been a major bottleneck in their applications for past decades. Two key reasons behind may be: (1) the slow gradient-based learning algorithms are extensively used to train neural networks, and (2) all the parameters of the networks are tuned iteratively by using such learning algorithms. Unlike these conventional implementations, this paper proposes a new learning algorithm called extreme learning machine (ELM) for single-hidden layer feedforward neural networks (SLFNs) which randomly chooses hidden nodes and analytically determines the output weights of SLFNs. In theory, this algorithm tends to provide good generalization performance at extremely fast learning speed. The experimental results based on a few artificial and real benchmark function approximation and classification problems including very large complex applications show that the new algorithm can produce good generalization performance in most cases and can learn thousands of times faster than conventional popular learning algorithms for feedforward neural networks.11For the preliminary idea of the \{ELM\} algorithm, refer to “Extreme Learning Machine: A New Learning Scheme of Feedforward Neural Networks”, Proceedings of International Joint Conference on Neural Networks (IJCNN2004), Budapest, Hungary, 25–29 July, 2004. "
}

@ARTICLE{6035797,
	author={G. B. Huang and H. Zhou and X. Ding and R. Zhang},
	journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	title={Extreme Learning Machine for Regression and Multiclass Classification},
	year={2012},
	volume={42},
	number={2},
	pages={513-529},
	keywords={computational complexity;feedforward neural nets;learning (artificial intelligence);least squares approximations;optimisation;pattern classification;polynomials;regression analysis;support vector machines;ELM;LS-SVM;PSVM;binary classification applications;computational complexity;conventional feedforward neural networks;extreme learning machine;feature mapping;generalized single-hidden-layer feedforward networks;least square support vector machine;multiclass classification;optimization method;polynomial network;proximal support vector machine;regression;regularization algorithms;Approximation methods;Feedforward neural networks;Kernel;Machine learning;Optimization;Support vector machines;Training;Extreme learning machine (ELM);feature mapping;kernel;least square support vector machine (LS-SVM);proximal support vector machine (PSVM);regularization network},
	doi={10.1109/TSMCB.2011.2168604},
	ISSN={1083-4419},
	month={April},}

@article{doi:10.11613/BM.2014.003,
	author = {Sperandei Sandro,},
	title = {Understanding logistic regression analysis},
	journal = {biochem},
	volume = {24},
	number = {1},
	pages = {12-18},
	year = {2014},
	doi = {10.11613/BM.2014.003},
	
	URL = {http://www.e-sciencecentral.org/articles/?scid=SC000000803},
	eprint = {http://www.e-sciencecentral.org/articles/?scid=SC000000803}
}

@article{Mood01022010,
	author = {Mood, Carina}, 
	title = {Logistic Regression: Why We Cannot Do What We Think We Can Do, and What We Can Do About It},
	volume = {26}, 
	number = {1}, 
	pages = {67-82}, 
	year = {2010}, 
	doi = {10.1093/esr/jcp006}, 
	abstract ={Logistic regression estimates do not behave like linear regression estimates in one important respect: They are affected by omitted variables, even when these variables are unrelated to the independent variables in the model. This fact has important implications that have gone largely unnoticed by sociologists. Importantly, we cannot straightforwardly interpret log-odds ratios or odds ratios as effect measures, because they also reflect the degree of unobserved heterogeneity in the model. In addition, we cannot compare log-odds ratios or odds ratios for similar models across groups, samples, or time points, or across models with different independent variables in a sample. This article discusses these problems and possible ways of overcoming them.}, 
	URL = {http://esr.oxfordjournals.org/content/26/1/67.abstract}, 
	eprint = {http://esr.oxfordjournals.org/content/26/1/67.full.pdf+html}, 
	journal = {European Sociological Review} 
}

@ARTICLE{6313426, 
	author={J. M. Keller and M. R. Gray and J. A. Givens}, 
	journal={IEEE Transactions on Systems, Man, and Cybernetics}, 
	title={A fuzzy K-nearest neighbor algorithm}, 
	year={1985}, 
	volume={SMC-15}, 
	number={4}, 
	pages={580-585}, 
	keywords={Bayes methods;fuzzy set theory;pattern recognition;Bayes decision;K-nearest neighbor decision rule;classification;fuzzy memberships;fuzzy sets;labeled samples;pattern recognition;Classification algorithms;Error analysis;Iris;Pattern recognition;Prototypes;Support vector machine classification;Vectors}, 
	doi={10.1109/TSMC.1985.6313426}, 
	ISSN={0018-9472}, 
	month={July},}

@article{doi:10.1021/ci034160g,
	author = {Svetnik, Vladimir and Liaw, Andy and Tong, Christopher and Culberson, J. Christopher and Sheridan, Robert P. and Feuston, Bradley P.}
	title = {Random Forest:  A Classification and Regression Tool for Compound Classification and QSAR Modeling},
	journal = {Journal of Chemical Information and Computer Sciences},
	volume = {43},
	number = {6},
	pages = {1947-1958},
	year = {2003},
	doi = {10.1021/ci034160g},
	note ={PMID: 14632445},
	
	URL = { 
	http://dx.doi.org/10.1021/ci034160g
	
	},
	eprint = { 
	http://dx.doi.org/10.1021/ci034160g
	
	}
	
}

@article {WIDM:WIDM1072,
	author = {Boulesteix, Anne-Laure and Janitza, Silke and Kruppa, Jochen and König, Inke R.},
	title = {Overview of random forest methodology and practical guidance with emphasis on computational biology and bioinformatics},
	journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
	volume = {2},
	number = {6},
	publisher = {John Wiley & Sons, Inc.},
	issn = {1942-4795},
	url = {http://dx.doi.org/10.1002/widm.1072},
	doi = {10.1002/widm.1072},
	pages = {493--507},
	year = {2012},
}

@article{FREUND1997119,
	title = "A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting",
	journal = "Journal of Computer and System Sciences",
	volume = "55",
	number = "1",
	pages = "119 - 139",
	year = "1997",
	note = "",
	issn = "0022-0000",
	doi = "http://dx.doi.org/10.1006/jcss.1997.1504",
	url = "http://www.sciencedirect.com/science/article/pii/S002200009791504X",
	author = "Yoav Freund and Robert E Schapire",
	
}

@Article{Bergstra2006,
	author="Bergstra, James
	and Casagrande, Norman
	and Erhan, Dumitru
	and Eck, Douglas
	and K{\'e}gl, Bal{\'a}zs",
	title="Aggregate features and ADABOOST for music classification",
	journal="Machine Learning",
	year="2006",
	volume="65",
	number="2",
	pages="473--484",
	abstract="We present an algorithm that predicts musical genre and artist from an audio waveform. Our method uses the ensemble learner ADABOOST to select from a set of audio features that have been extracted from segmented audio and then aggregated. Our classifier proved to be the most effective method for genre classification at the recent MIREX 2005 international contests in music information extraction, and the second-best method for recognizing artists. This paper describes our method in detail, from feature extraction to song classification, and presents an evaluation of our method on three genre databases and two artist-recognition databases. Furthermore, we present evidence collected from a variety of popular features and classifiers that the technique of classifying features aggregated over segments of audio is better than classifying either entire songs or individual short-timescale features.",
	issn="1573-0565",
	doi="10.1007/s10994-006-9019-7",
	url="http://dx.doi.org/10.1007/s10994-006-9019-7"
}

@article{rojas2009adaboost,
	added-at = {2013-04-07T20:20:44.000+0200},
	author = {Rojas, Raúl},
	biburl = {http://www.bibsonomy.org/bibtex/27a6b67dc2a8758139dd270692c3929f1/bsc},
	interhash = {12dab9863857f6a0079c677331f3ad30},
	intrahash = {7a6b67dc2a8758139dd270692c3929f1},
	keywords = {AdaBoost ba2013},
	timestamp = {2014-02-13T14:07:01.000+0100},
	title = {AdaBoost and the Super Bowl of Classifiers A Tutorial Introduction to Adaptive Boosting, {Computer Science Department}, {Freie Universit\"at, Berlin}},
	year = 2009
}

@inproceedings{rish2001empirical,
	title={An empirical study of the naive Bayes classifier},
	author={Rish, Irina},
	booktitle={IJCAI 2001 workshop on empirical methods in artificial intelligence},
	volume={3},
	number={22},
	pages={41--46},
	year={2001},
	organization={IBM New York}
}

@Inbook{Lewis1998,
	author="Lewis, David D.",
	editor="N{\'e}dellec, Claire
	and Rouveirol, C{\'e}line",
	title="Naive (Bayes) at forty: The independence assumption in information retrieval",
	bookTitle="Machine Learning: ECML-98: 10th European Conference on Machine Learning Chemnitz, Germany, April 21--23, 1998 Proceedings",
	year="1998",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="4--15",
	isbn="978-3-540-69781-7",
	doi="10.1007/BFb0026666",
	url="http://dx.doi.org/10.1007/BFb0026666"
}

@Inbook{Chen2006,
	author="Chen, Tung-Shou
	and Lin, Chih-Chiang
	and Chiu, Yung-Hsing
	and Lin, Hsin-Lan
	and Chen, Rong-Chang",
	editor="Huang, De-Shuang
	and Li, Kang
	and Irwin, George William",
	title="A New Binary Classifier: Clustering-Launched Classification",
	bookTitle="Computational Intelligence: International Conference on Intelligent Computing, ICIC 2006, Kunming, China, August 16-19, 2006. Proceedings, Part II",
	year="2006",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="278--283",
	isbn="978-3-540-37275-2",
	doi="10.1007/11816171_35",
	url="http://dx.doi.org/10.1007/11816171_35"
}

@article{Batista:2004:SBS:1007730.1007735,
	author = {Batista, Gustavo E. A. P. A. and Prati, Ronaldo C. and Monard, Maria Carolina},
	title = {A Study of the Behavior of Several Methods for Balancing Machine Learning Training Data},
	journal = {SIGKDD Explor. Newsl.},
	issue_date = {June 2004},
	volume = {6},
	number = {1},
	month = jun,
	year = {2004},
	issn = {1931-0145},
	pages = {20--29},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/1007730.1007735},
	doi = {10.1145/1007730.1007735},
	acmid = {1007735},
	publisher = {ACM},
	address = {New York, NY, USA},
} 

@ARTICLE{4309452, 
	journal={IEEE Transactions on Systems, Man, and Cybernetics}, 
	title={Two Modifications of CNN}, 
	year={1976}, 
	volume={SMC-6}, 
	number={11}, 
	pages={769-772}, 
	keywords={Bibliographies;Cellular neural networks;Computer science;Cybernetics;Fuzzy control;Fuzzy logic;Fuzzy set theory;Fuzzy sets;Minimization methods;Neural networks}, 
	doi={10.1109/TSMC.1976.4309452}, 
	ISSN={0018-9472}, 
	month={Nov},}

@ARTICLE{1056066, 
	author={K. Gowda and G. Krishna}, 
	journal={IEEE Transactions on Information Theory}, 
	title={The condensed nearest neighbor rule using the concept of mutual nearest neighborhood (Corresp.)}, 
	year={1979}, 
	volume={25}, 
	number={4}, 
	pages={488-490}, 
	keywords={Pattern classification;Biological cells;Cellular neural networks;DNA;Extraterrestrial measurements;Humans;Image analysis;Iterative algorithms;Nearest neighbor searches;Neural networks;Testing}, 
	doi={10.1109/TIT.1979.1056066}, 
	ISSN={0018-9448}, 
	month={Jul},}

@INPROCEEDINGS{Kubat97addressingthe,
	author = {Miroslav Kubat and Stan Matwin},
	title = {Addressing the Curse of Imbalanced Training Sets: One-Sided Selection},
	booktitle = {In Proceedings of the Fourteenth International Conference on Machine Learning},
	year = {1997},
	pages = {179--186},
	publisher = {Morgan Kaufmann}
}

@inproceedings{Laurikkala:2001:IID:648155.757340,
	author = {Laurikkala, Jorma},
	title = {Improving Identification of Difficult Small Classes by Balancing Class Distribution},
	booktitle = {Proceedings of the 8th Conference on AI in Medicine in Europe: Artificial Intelligence Medicine},
	series = {AIME '01},
	year = {2001},
	isbn = {3-540-42294-3},
	pages = {63--66},
	numpages = {4},
	url = {http://dl.acm.org/citation.cfm?id=648155.757340},
	acmid = {757340},
	publisher = {Springer-Verlag},
	address = {London, UK, UK},
} 

@inproceedings{mani2003knn,
	title={kNN approach to unbalanced data distributions: a case study involving information extraction},
	author={Zhang, I and Mani, Inderjeet},
	booktitle={Proceedings of workshop on learning from imbalanced datasets},
	year={2003}
}

@article{Smith:2014:ILA:2843614.2843686,
	author = {Smith, Michael R. and Martinez, Tony and Giraud-Carrier, Christophe},
	title = {An Instance Level Analysis of Data Complexity},
	journal = {Mach. Learn.},
	issue_date = {May       2014},
	volume = {95},
	number = {2},
	month = may,
	year = {2014},
	issn = {0885-6125},
	pages = {225--256},
	numpages = {32},
	url = {http://dx.doi.org/10.1007/s10994-013-5422-z},
	doi = {10.1007/s10994-013-5422-z},
	acmid = {2843686},
	publisher = {Kluwer Academic Publishers},
	address = {Hingham, MA, USA},
	keywords = {Data complexity, Dataset hardness, Instance hardness},
} 

@article{Chawla:2002:SSM:1622407.1622416,
	author = {Chawla, Nitesh V. and Bowyer, Kevin W. and Hall, Lawrence O. and Kegelmeyer, W. Philip},
	title = {SMOTE: Synthetic Minority Over-sampling Technique},
	journal = {J. Artif. Int. Res.},
	issue_date = {January 2002},
	volume = {16},
	number = {1},
	month = jun,
	year = {2002},
	issn = {1076-9757},
	pages = {321--357},
	numpages = {37},
	url = {http://dl.acm.org/citation.cfm?id=1622407.1622416},
	acmid = {1622416},
	publisher = {AI Access Foundation},
	address = {USA},
} 

@INPROCEEDINGS{4633969, 
	author={Haibo He and Yang Bai and E. A. Garcia and Shutao Li}, 
	booktitle={2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)}, 
	title={ADASYN: Adaptive synthetic sampling approach for imbalanced learning}, 
	year={2008}, 
	pages={1322-1328}, 
	keywords={learning (artificial intelligence);pattern classification;sampling methods;statistical distributions;adaptive synthetic sampling approach;classification decision boundary;imbalanced data classification;imbalanced data set learning;weighted distribution;Bioinformatics;Boosting;Cancer;Data analysis;Data mining;Decision trees;Helium;Machine learning;Sampling methods;Space technology}, 
	doi={10.1109/IJCNN.2008.4633969}, 
	ISSN={2161-4393}, 
	month={June},}

@inproceedings{batista2003balancing,
	title={Balancing Training Data for Automated Annotation of Keywords: a Case Study.},
	author={Batista, Gustavo EAPA and Bazzan, Ana LC and Monard, Maria Carolina},
	booktitle={WOB},
	pages={10--18},
	year={2003}
}

@article{Chawla:2004:ESI:1007730.1007733,
	author = {Chawla, Nitesh V. and Japkowicz, Nathalie and Kotcz, Aleksander},
	title = {Editorial: Special Issue on Learning from Imbalanced Data Sets},
	journal = {SIGKDD Explor. Newsl.},
	issue_date = {June 2004},
	volume = {6},
	number = {1},
	month = jun,
	year = {2004},
	issn = {1931-0145},
	pages = {1--6},
	numpages = {6},
	url = {http://doi.acm.org/10.1145/1007730.1007733},
	doi = {10.1145/1007730.1007733},
	acmid = {1007733},
	publisher = {ACM},
	address = {New York, NY, USA},
} 

@article {PMID:25988841,
	Title = {Application of high-dimensional feature selection: evaluation for genomic prediction in man},
	Author = {Bermingham, ML and Pong-Wong, R and Spiliopoulou, A and Hayward, C and Rudan, I and Campbell, H and Wright, AF and Wilson, JF and Agakov, F and Navarro, P and Haley, CS},
	DOI = {10.1038/srep10312},
	Volume = {5},
	Year = {2015},
	Journal = {Scientific reports},
	ISSN = {2045-2322},
	Pages = {10312},
	URL = {http://europepmc.org/articles/PMC4437376},
}

@article{Guyon:2003:IVF:944919.944968,
	author = {Guyon, Isabelle and Elisseeff, Andr{\'e}},
	title = {An Introduction to Variable and Feature Selection},
	journal = {J. Mach. Learn. Res.},
	issue_date = {3/1/2003},
	volume = {3},
	month = mar,
	year = {2003},
	issn = {1532-4435},
	pages = {1157--1182},
	numpages = {26},
	url = {http://dl.acm.org/citation.cfm?id=944919.944968},
	acmid = {944968},
	publisher = {JMLR.org},
} 

@inproceedings{mccallum1998comparison,
	title={A comparison of event models for naive bayes text classification},
	author={McCallum, Andrew and Nigam, Kamal and others},
	booktitle={AAAI-98 workshop on learning for text categorization},
	volume={752},
	pages={41--48},
	year={1998}
}

@inproceedings{John:1995:ECD:2074158.2074196,
	author = {John, George H. and Langley, Pat},
	title = {Estimating Continuous Distributions in Bayesian Classifiers},
	booktitle = {Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence},
	series = {UAI'95},
	year = {1995},
	isbn = {1-55860-385-9},
	location = {Montr\&\#233;al, Qu\&\#233;, Canada},
	pages = {338--345},
	numpages = {8},
	url = {http://dl.acm.org/citation.cfm?id=2074158.2074196},
	acmid = {2074196},
	publisher = {Morgan Kaufmann Publishers Inc.},
	address = {San Francisco, CA, USA},
} 

@misc{Lichman:2013 ,
	author = "M. Lichman",
	year = "2013",
	title = "{UCI} Machine Learning Repository",
	url = "http://archive.ics.uci.edu/ml",
	institution = "University of California, Irvine, School of Information and Computer Sciences" } 

@article{scikit-learn,
	title={Scikit-learn: Machine Learning in {P}ython},
	author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
	and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
	and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
	Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
	journal={Journal of Machine Learning Research},
	volume={12},
	pages={2825--2830},
	year={2011}
}

@ARTICLE{7140733,
	author={A. Akusok and K. M. Björk and Y. Miche and A. Lendasse},
	journal={IEEE Access},
	title={High-Performance Extreme Learning Machines: A Complete Toolbox for Big Data Applications},
	year={2015},
	volume={3},
	pages={1011-1025},
	keywords={Learning systems;Machine learning;Performance evaluation},
	doi={10.1109/ACCESS.2015.2450498},
	ISSN={2169-3536},
	month={},}

@article{lemaitre2016imbalanced,
	author    = {Guillaume Lema\^{i}tre and
	Fernando Nogueira and
	Christos K. Aridas},
	title     = {Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning},
	journal   = {CoRR},
	volume    = {abs/1609.06570},
	year      = {2016},
	url       = {http://arxiv.org/abs/1609.06570}
}

@article{Li2006772,
	title = "The evaluation of consumer loans using support vector machines",
	journal = "Expert Systems with Applications",
	volume = "30",
	number = "4",
	pages = "772-782",
	year = "2006",
	note = "",
	issn = "0957-4174",
	doi = "http://dx.doi.org/10.1016/j.eswa.2005.07.041",
	url = "http://www.sciencedirect.com/science/article/pii/S0957417405001739",
	author = "Sheng-Tun Li and Weissor Shiue and Meng-Huah Huang",
	keywords = "Consumer loans",
	keywords = "Support vector machines",
	keywords = "Artificial neural networks",
	keywords = "Credit scoring",
	keywords = "Decision making ",
	abstract = "The commencement of the Basel \{II\} requirement, popularization of consumer loans and the intense competition in financial market has increased the awareness of the critical delinquency issue for financial institutions in granting loans to potential applicants. In the past few decades, the scheme of artificial neural networks has been successfully applied to the financial field. Recently, the Support Vector Machine (SVM) has emerged as the better neural network in dealing with classification and forecasting problems due to its superior features of generalization performance and global optimum. This study develops a loan evaluation model using \{SVM\} to identify potential applicants for consumer loans. In addition to conducting experiments on performance comparison via cross-validation and paired t test, we analyze misclassification errors in terms of Type I and Type \{II\} and their effect on selecting network parameters of SVM. The analysis findings facilitate the development of a useful visual decision-support tool. The experimental results using a real-world data set reveal that \{SVM\} surpasses traditional neural network models in generalization performance and visualization via the visual tool, which helps decision makers determine appropriate loan evaluation strategies. "
}






