@article{world2015TB,
	title={Global tuberculosis report 2015},
	author={{World Health Organisation}},
	publisher={World Health Organization}
}

@article{Lackey:10356751520150601,
	Abstract = {Background: Although tuberculosis (TB) is usually curable with antibiotics, poor adherence to medication can lead to increased transmission, drug resistance, and death. Prior research has shown several factors to be associated with poor adherence, but this problem remains a substantial barrier to global TB control. We studied patients in a high-incidence district of Lima, Peru to identify factors associated with premature termination of treatment (treatment default). Methods: We conducted a prospective cohort study of adult smear-positive TB patients enrolled between January 2010 and December 2011 with no history of TB disease. Descriptive statistics and multivariable logistic regression analyses were performed to determine risk factors associated with treatment default. Results: Of the 1233 patients studied, 127 (10%) defaulted from treatment. Patients who defaulted were more likely to have used illegal drugs (OR = 4.78, 95% CI: 3.05-7.49), have multidrug-resistant TB (OR = 3.04, },
	Author = {Lackey, Brian and Seas, Carlos and Van der Stuyft, Patrick and Otero, Larissa},
	ISSN = {19326203},
	Journal = {PLoS ONE},
	Keywords = {TUBERCULOSIS -- Treatment, DISEASE incidence, MULTIDRUG resistance, PUBLIC health, PERU, LIMA (Peru), Research Article},
	Number = {6},
	Pages = {1-11},
	Title = {Patient Characteristics Associated with Tuberculosis Treatment Default: A Cohort Study in a High-Incidence Area of Lima, Peru.},
	Volume = {10},
	URL = {http://search.ebscohost.com/login.aspx?direct=true&db=aph&AN=103567515&site=ehost-live},
	Year = {2015},
}

@article{muture:6660173120110101,
	Abstract = {The article offers information on a study conducted by the authors on factors related to treatment default in tuberculosis patients in Nairobi, Kenya. The study included 945 defaulters and others who completed the treatment between 2006-2008. It states that they attributed default to ignorance, traveling away from treatment facility and feeling better. Other independent factors included alcohol abuse, low income, use of herbal medication and male gender.},
	ISSN = {14712458},
	Author={Muture, Bernard and Keraka, Margaret N and Kimuu, Peter K and Kabiru, Ephantus W and Ombeka, Victor O and Oguya, Francis},
	Journal = {BMC Public Health},
	Keywords = {TUBERCULOSIS -- Treatment, ALCOHOLISM, HERBAL medicine, NAIROBI (Kenya), KENYA},
	Number = {1},
	Pages = {696-105},
	Title = {Factors associated with default from treatment among tuberculosis patients in nairobi province, Kenya: A case control study.},
	Volume = {11},
	URL = {http://search.ebscohost.com/login.aspx?direct=true&db=aph&AN=66601731&site=ehost-live},
	month={September},
	Year = {2011},
}

@ARTICLE{Jha:10.1371/journal.pone.0008873,
	author = {Jha, Ugra Mohan AND Satyanarayana, Srinath AND Dewan, Puneet K. AND Chadha, Sarabjit AND Wares, Fraser AND Sahu, Suvanand AND Gupta, Devesh AND Chauhan, L. S.},
	journal = {PLoS ONE},
	publisher = {Public Library of Science},
	title = {Risk Factors for Treatment Default among Re-Treatment Tuberculosis Patients in India, 2006},
	year = {2010},
	month = {January},
	volume = {5},
	url = {http://dx.doi.org/10.1371%2Fjournal.pone.0008873},
	pages = {1-7},
	abstract = {<sec>
	<title>Setting</title>
	<p>Under India's Revised National Tuberculosis Control Programme (RNTCP), &gt;15% of previously-treated patients in the reported 2006 patient cohort defaulted from anti-tuberculosis treatment.</p>
	</sec><sec>
	<title>Objective</title>
	<p>To assess the timing, characteristics, and risk factors for default amongst re-treatment TB patients.</p>
	</sec><sec>
	<title>Methodology</title>
	<p>For this case-control study, in 90 randomly-selected programme units treatment records were abstracted from all 2006 defaulters from the RNTCP re-treatment regimen (cases), with one consecutively-selected non-defaulter per case. Patients who interrupted anti-tuberculosis treatment for &gt;2 months were classified as defaulters.</p>
	</sec><sec>
	<title>Results</title>
	<p>1,141 defaulters and 1,189 non-defaulters were included. The median duration of treatment prior to default was 81 days (25%?75% interquartile range 44?117 days) and documented retrieval efforts after treatment interruption were inadequate. Defaulters were more likely to have been male (adjusted odds ratio [aOR] 1.4, 95% confidence interval [CI] 1.2?1.7), have previously defaulted anti-tuberculosis treatment (aOR 1.3 95%CI 1.1?1.6], have previous treatment from non-RNTCP providers (AOR 1.3, 95%CI 1.0?1.6], or have public health facility-based treatment observation (aOR 1.3, 95%CI 1.1?1.6).</p>
	</sec><sec>
	<title>Conclusions</title>
	<p>Amongst the large number of re-treatment patients in India, default occurs early and often. Improved pre-treatment counseling and community-based treatment provision may reduce default rates. Efforts to retrieve treatment interrupters prior to default require strengthening.</p>
	</sec>},
	number = {1},
	doi = {10.1371/journal.pone.0008873}
}

@article {jittimanee:10.1111/j.1440-172X.2007.00650.x,
	author = {Jittimanee, Sirinapha X and Madigan, Elizabeth A and Jittimanee, Suksont and Nontasood, Chonkanok},
	title = {Treatment default among urban tuberculosis patients, Thailand},
	journal = {International Journal of Nursing Practice},
	volume = {13},
	number = {6},
	publisher = {Blackwell Publishing Asia},
	issn = {1440-172X},
	url = {http://dx.doi.org/10.1111/j.1440-172X.2007.00650.x},
	doi = {10.1111/j.1440-172X.2007.00650.x},
	pages = {354--362},
	keywords = {default, Donabedian, process, Thailand, tuberculosis, urban},
	year = {2007},
}

@article{chan:2003prevalence,
	title={Prevalence and predictors of default from tuberculosis treatment in Hong Kong},
	author={Chan-Yeung, M and Noertjojo, K and Leung, CC and Chan, SL and Tam, CM},
	journal={Hong Kong Medical Journal},
	volume={9},
	number={4},
	pages={263-270},
	year={2003},
	publisher={CHURCHILL LIVINGSTONE ASIA PACIFIC}
}

@article{cherkaoui:19326203,
	Abstract = {Setting: Public tuberculosis (TB) clinics in urban Morocco. Objective: Explore risk factors for TB treatment default and develop a prediction tool. Assess consequences of default, specifically risk for transmission or development of drug resistance. Design: Case-control study comparing patients who defaulted from TB treatment and patients who completed it using quantitative methods and open-ended questions. Results were interpreted in light of health professionals’ perspectives from a parallel study. A predictive model and simple tool to identify patients at high risk of default were developed. Sputum from cases with pulmonary TB was collected for smear and drug susceptibility testing. Results: 91 cases and 186 controls enrolled. Independent risk factors for default included current smoking, retreatment, work interference with adherence, daily directly observed therapy, side effects, quick symptom resolution, and not knowing one’s treatment duration. Age >50 years, never smoking, and },
	Author = {Cherkaoui, Imad and Sabouni, Radia and Ghali, Iraqi and Kizub, Darya and Billioux, Alexander C. and Bennani, Kenza and Bourkadi, Jamal Eddine and Benmamoun, Abderrahmane and Lahlou, Ouafae and Aouad, Rajae El and Dooley, Kelly E.},
	ISSN = {19326203},
	Journal = {PLoS ONE},
	Keywords = {TUBERCULOSIS patients, TUBERCULOSIS -- Treatment, THERAPEUTICS -- Complications, DRUG resistance, TUBERCULOSIS, QUANTITATIVE research, TREATMENT duration (Medical care), MEDICAL personnel, TRANSMISSION, MOROCCO, Bacterial diseases, Behavioral and social aspects of health, Global health, Health care, Health care policy, Health risk analysis, Health systems strengthening, Infectious disease control, Infectious diseases, Medicine and health sciences, Public and occupational health, Research Article, Socioeconomic aspects of health, Tropical diseases, Tuberculosis},
	Number = {4},
	Pages = {1-9},
	Title = {Treatment Default amongst Patients with Tuberculosis in Urban Morocco: Predicting and Explaining Default and Post-Default Sputum Smear and Drug Susceptibility Results.},
	Volume = {9},
	URL = {http://search.ebscohost.com/login.aspx?direct=true&db=aph&AN=95818218&site=ehost-live},
	month={April},
	Year = {2014},
}

@article{Shargie:10.1371/journal.pmed.0040037,
	author = {Shargie, Estifanos Biru AND Lindtjorn, Bernt},
	journal = {PLoS Med},
	publisher = {Public Library of Science},
	title = {Determinants of Treatment Adherence Among Smear-Positive Pulmonary
	Tuberculosis Patients in Southern Ethiopia},
	year = {2007},
	month = {February},
	volume = {4},
	url = {http://dx.doi.org/10.1371%2Fjournal.pmed.0040037},
	pages = {1-8},
	abstract = {
	<p>A prospective cohort study of smear-positive tuberculosis patients at an Ethiopian
	hospital found treatment default rates to be high; the main factors relate to physical
	access to the treatment centre.</p>
	},
	number = {2},
	doi = {10.1371/journal.pmed.0040037}
}

@article{Luo20097562,
	title = "Prediction model building with clustering-launched classification and support vector machines in credit scoring",
	journal = "Expert Systems with Applications",
	volume = "36",
	number = "4",
	pages = "7562-7566",
	year = "2009",
	note = "",
	issn = "0957-4174",
	doi = "http://dx.doi.org/10.1016/j.eswa.2008.09.028",
	url = "http://www.sciencedirect.com/science/article/pii/S0957417408006829",
	author = "Shu-Ting Luo and Bor-Wen Cheng and Chun-Hung Hsieh",
	keywords = "Credit scoring",
	keywords = "Support vector machine",
	keywords = "Clustering-launched classification ",
	abstract = "Abstract Recently, credit scoring has become a very important task as credit cards are now widely used by customers. A method that can accurately predict credit scoring is greatly needed and good prediction techniques can help to predict credit more accurately. One powerful classifier, the support vector machine (SVM), was successfully applied to a wide range of domains. In recent years, researchers have applied the SVM-based in the prediction of credit scoring, and the results have been shown it to be effective. In this study, two real world credit datasets in the University of California Irvine Machine Learning Repository were selected. \{SVM\} and a new classifier, clustering-launched classification (CLC), were employed to predict the accuracy of credit scoring. The advantages of using \{CLC\} are that it can classify data efficiently and only need one parameter needs to be decided. In substance, the results show that \{CLC\} is better than SVM. Therefore, \{CLC\} is an effective tool to predict credit scoring. "
}

@article{Danenas20153194,
	title = "Selection of Support Vector Machines based classifiers for credit risk domain",
	journal = "Expert Systems with Applications",
	volume = "42",
	number = "6",
	pages = "3194-3204",
	year = "2015",
	note = "",
	issn = "0957-4174",
	doi = "http://dx.doi.org/10.1016/j.eswa.2014.12.001",
	url = "http://www.sciencedirect.com/science/article/pii/S0957417414007660",
	author = "Paulius Danenas and Gintautas Garsva",
	keywords = "Support Vector Machines",
	keywords = "SVM",
	keywords = "Particle swarm optimization",
	keywords = "Credit risk",
	keywords = "Default assessment",
	keywords = "Classification ",
	abstract = "Abstract This paper describes an approach for credit risk evaluation based on linear Support Vector Machines classifiers, combined with external evaluation and sliding window testing, with focus on application on larger datasets. It presents a technique for optimal linear \{SVM\} classifier selection based on particle swarm optimization technique, providing significant amount of focus on imbalanced learning issue. It is compared to other classifiers in terms of accuracy and identification of each class. Experimental classification performance results, obtained using real world financial dataset from \{SEC\} \{EDGAR\} database, lead to conclusion that proposed technique is capable to produce results, comparable to other classifiers, such as logistic regression and \{RBF\} network, and thus be can be an appealing option for future development of real credit risk evaluation models. "
}

@article{hsu2003practical,
	title={A practical guide to support vector classification},
	author={Hsu, Chih-Wei and Chang, Chih-Chung and Lin, Chih-Jen and others},
	journal={Department of Computer Science, National Taiwan University}
	year={2003}
}

@Inbook{Wang2003,
	author="Wang, Sun-Chong",
	chapter="Artificial Neural Network",
	title="Interdisciplinary Computing in Java Programming",
	year="2003",
	publisher="Springer US",
	address="Boston, MA",
	pages="81-100",
	isbn="978-1-4615-0377-4",
	doi="10.1007/978-1-4615-0377-4_5",
	url="http://dx.doi.org/10.1007/978-1-4615-0377-4_5"
}

@article{Hornik1991251,
	title = "Approximation capabilities of multilayer feedforward networks",
	journal = "Neural Networks",
	volume = "4",
	number = "2",
	pages = "251-257",
	year = "1991",
	note = "",
	issn = "0893-6080",
	doi = "http://dx.doi.org/10.1016/0893-6080(91)90009-T",
	url = "http://www.sciencedirect.com/science/article/pii/089360809190009T",
	author = "Kurt Hornik",
	keywords = "Multilayer feedforward networks",
	keywords = "Activation function",
	keywords = "Universal approximation capabilities",
	keywords = "Input environment measure",
	keywords = "Lp(Î¼) approximation",
	keywords = "Uniform approximation",
	keywords = "Sobolev spaces",
	keywords = "Smooth approximation ",
	abstract = "We show that standard multilayer feedforward networks with as few as a single hidden layer and arbitrary bounded and nonconstant activation function are universal approximators with respect to Lp(Î¼) performance criteria, for arbitrary finite input environment measures Î¼, provided only that sufficiently many hidden units are available. If the activation function is continuous, bounded and nonconstant, then continuous mappings can be learned uniformly over compact input sets. We also give very general conditions ensuring that networks with sufficiently smooth activation functions are capable of arbitrarily accurate approximation to a function and its derivatives. "
}

@article{Huang2006489,
	title = "Extreme learning machine: Theory and applications ",
	journal = "Neurocomputing ",
	volume = "70",
	number = "1–3",
	pages = "489 - 501",
	year = "2006",
	note = "Neural NetworksSelected Papers from the 7th Brazilian Symposium on Neural Networks (SBRN '04)7th Brazilian Symposium on Neural Networks ",
	issn = "0925-2312",
	doi = "http://dx.doi.org/10.1016/j.neucom.2005.12.126",
	url = "http://www.sciencedirect.com/science/article/pii/S0925231206000385",
	author = "Guang-Bin Huang and Qin-Yu Zhu and Chee-Kheong Siew",
	keywords = "Feedforward neural networks",
	keywords = "Back-propagation algorithm",
	keywords = "Extreme learning machine",
	keywords = "Support vector machine",
	keywords = "Real-time learning",
	keywords = "Random node ",
	abstract = "It is clear that the learning speed of feedforward neural networks is in general far slower than required and it has been a major bottleneck in their applications for past decades. Two key reasons behind may be: (1) the slow gradient-based learning algorithms are extensively used to train neural networks, and (2) all the parameters of the networks are tuned iteratively by using such learning algorithms. Unlike these conventional implementations, this paper proposes a new learning algorithm called extreme learning machine (ELM) for single-hidden layer feedforward neural networks (SLFNs) which randomly chooses hidden nodes and analytically determines the output weights of SLFNs. In theory, this algorithm tends to provide good generalization performance at extremely fast learning speed. The experimental results based on a few artificial and real benchmark function approximation and classification problems including very large complex applications show that the new algorithm can produce good generalization performance in most cases and can learn thousands of times faster than conventional popular learning algorithms for feedforward neural networks.11For the preliminary idea of the \{ELM\} algorithm, refer to “Extreme Learning Machine: A New Learning Scheme of Feedforward Neural Networks”, Proceedings of International Joint Conference on Neural Networks (IJCNN2004), Budapest, Hungary, 25–29 July, 2004. "
}

@ARTICLE{6035797,
	author={G. B. Huang and H. Zhou and X. Ding and R. Zhang},
	journal={IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	title={Extreme Learning Machine for Regression and Multiclass Classification},
	year={2012},
	volume={42},
	number={2},
	pages={513-529},
	keywords={computational complexity;feedforward neural nets;learning (artificial intelligence);least squares approximations;optimisation;pattern classification;polynomials;regression analysis;support vector machines;ELM;LS-SVM;PSVM;binary classification applications;computational complexity;conventional feedforward neural networks;extreme learning machine;feature mapping;generalized single-hidden-layer feedforward networks;least square support vector machine;multiclass classification;optimization method;polynomial network;proximal support vector machine;regression;regularization algorithms;Approximation methods;Feedforward neural networks;Kernel;Machine learning;Optimization;Support vector machines;Training;Extreme learning machine (ELM);feature mapping;kernel;least square support vector machine (LS-SVM);proximal support vector machine (PSVM);regularization network},
	doi={10.1109/TSMCB.2011.2168604},
	ISSN={1083-4419},
	month={April},}

@article{doi:10.11613/BM.2014.003,
	author = {Sperandei Sandro,},
	title = {Understanding logistic regression analysis},
	journal = {biochem},
	volume = {24},
	number = {1},
	pages = {12-18},
	year = {2014},
	doi = {10.11613/BM.2014.003},
	
	URL = {http://www.e-sciencecentral.org/articles/?scid=SC000000803},
	eprint = {http://www.e-sciencecentral.org/articles/?scid=SC000000803}
}

@article{Mood01022010,
	author = {Mood, Carina}, 
	title = {Logistic Regression: Why We Cannot Do What We Think We Can Do, and What We Can Do About It},
	volume = {26}, 
	number = {1}, 
	pages = {67-82}, 
	year = {2010}, 
	doi = {10.1093/esr/jcp006}, 
	abstract ={Logistic regression estimates do not behave like linear regression estimates in one important respect: They are affected by omitted variables, even when these variables are unrelated to the independent variables in the model. This fact has important implications that have gone largely unnoticed by sociologists. Importantly, we cannot straightforwardly interpret log-odds ratios or odds ratios as effect measures, because they also reflect the degree of unobserved heterogeneity in the model. In addition, we cannot compare log-odds ratios or odds ratios for similar models across groups, samples, or time points, or across models with different independent variables in a sample. This article discusses these problems and possible ways of overcoming them.}, 
	URL = {http://esr.oxfordjournals.org/content/26/1/67.abstract}, 
	eprint = {http://esr.oxfordjournals.org/content/26/1/67.full.pdf+html}, 
	journal = {European Sociological Review} 
}

@ARTICLE{6313426, 
	author={J. M. Keller and M. R. Gray and J. A. Givens}, 
	journal={IEEE Transactions on Systems, Man, and Cybernetics}, 
	title={A fuzzy K-nearest neighbor algorithm}, 
	year={1985}, 
	volume={SMC-15}, 
	number={4}, 
	pages={580-585}, 
	keywords={Bayes methods;fuzzy set theory;pattern recognition;Bayes decision;K-nearest neighbor decision rule;classification;fuzzy memberships;fuzzy sets;labeled samples;pattern recognition;Classification algorithms;Error analysis;Iris;Pattern recognition;Prototypes;Support vector machine classification;Vectors}, 
	doi={10.1109/TSMC.1985.6313426}, 
	ISSN={0018-9472}, 
	month={July},}

@article{doi:10.1021/ci034160g,
	author = {Svetnik, Vladimir and Liaw, Andy and Tong, Christopher and Culberson, J. Christopher and Sheridan, Robert P. and Feuston, Bradley P.}
	title = {Random Forest:  A Classification and Regression Tool for Compound Classification and QSAR Modeling},
	journal = {Journal of Chemical Information and Computer Sciences},
	volume = {43},
	number = {6},
	pages = {1947-1958},
	year = {2003},
	doi = {10.1021/ci034160g},
	note ={PMID: 14632445},
	
	URL = { 
	http://dx.doi.org/10.1021/ci034160g
	
	},
	eprint = { 
	http://dx.doi.org/10.1021/ci034160g
	
	}
	
}

@article {WIDM:WIDM1072,
	author = {Boulesteix, Anne-Laure and Janitza, Silke and Kruppa, Jochen and König, Inke R.},
	title = {Overview of random forest methodology and practical guidance with emphasis on computational biology and bioinformatics},
	journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
	volume = {2},
	number = {6},
	publisher = {John Wiley & Sons, Inc.},
	issn = {1942-4795},
	url = {http://dx.doi.org/10.1002/widm.1072},
	doi = {10.1002/widm.1072},
	pages = {493--507},
	year = {2012},
}

@article{FREUND1997119,
	title = "A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting",
	journal = "Journal of Computer and System Sciences",
	volume = "55",
	number = "1",
	pages = "119 - 139",
	year = "1997",
	note = "",
	issn = "0022-0000",
	doi = "http://dx.doi.org/10.1006/jcss.1997.1504",
	url = "http://www.sciencedirect.com/science/article/pii/S002200009791504X",
	author = "Yoav Freund and Robert E Schapire",
	
}

@Article{Bergstra2006,
	author="Bergstra, James
	and Casagrande, Norman
	and Erhan, Dumitru
	and Eck, Douglas
	and K{\'e}gl, Bal{\'a}zs",
	title="Aggregate features and ADABOOST for music classification",
	journal="Machine Learning",
	year="2006",
	volume="65",
	number="2",
	pages="473--484",
	abstract="We present an algorithm that predicts musical genre and artist from an audio waveform. Our method uses the ensemble learner ADABOOST to select from a set of audio features that have been extracted from segmented audio and then aggregated. Our classifier proved to be the most effective method for genre classification at the recent MIREX 2005 international contests in music information extraction, and the second-best method for recognizing artists. This paper describes our method in detail, from feature extraction to song classification, and presents an evaluation of our method on three genre databases and two artist-recognition databases. Furthermore, we present evidence collected from a variety of popular features and classifiers that the technique of classifying features aggregated over segments of audio is better than classifying either entire songs or individual short-timescale features.",
	issn="1573-0565",
	doi="10.1007/s10994-006-9019-7",
	url="http://dx.doi.org/10.1007/s10994-006-9019-7"
}

@article{rojas2009adaboost,
	added-at = {2013-04-07T20:20:44.000+0200},
	author = {Rojas, Raúl},
	biburl = {http://www.bibsonomy.org/bibtex/27a6b67dc2a8758139dd270692c3929f1/bsc},
	interhash = {12dab9863857f6a0079c677331f3ad30},
	intrahash = {7a6b67dc2a8758139dd270692c3929f1},
	keywords = {AdaBoost ba2013},
	timestamp = {2014-02-13T14:07:01.000+0100},
	title = {AdaBoost and the Super Bowl of Classifiers A Tutorial Introduction to Adaptive Boosting, {Computer Science Department}, {Freie Universit\"at, Berlin}},
	year = 2009
}

@inproceedings{rish2001empirical,
	title={An empirical study of the naive Bayes classifier},
	author={Rish, Irina},
	booktitle={IJCAI 2001 workshop on empirical methods in artificial intelligence},
	volume={3},
	number={22},
	pages={41--46},
	year={2001},
	organization={IBM New York}
}

@Inbook{Lewis1998,
	author="Lewis, David D.",
	editor="N{\'e}dellec, Claire
	and Rouveirol, C{\'e}line",
	title="Naive (Bayes) at forty: The independence assumption in information retrieval",
	bookTitle="Machine Learning: ECML-98: 10th European Conference on Machine Learning Chemnitz, Germany, April 21--23, 1998 Proceedings",
	year="1998",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="4--15",
	isbn="978-3-540-69781-7",
	doi="10.1007/BFb0026666",
	url="http://dx.doi.org/10.1007/BFb0026666"
}

@Inbook{Chen2006,
	author="Chen, Tung-Shou
	and Lin, Chih-Chiang
	and Chiu, Yung-Hsing
	and Lin, Hsin-Lan
	and Chen, Rong-Chang",
	editor="Huang, De-Shuang
	and Li, Kang
	and Irwin, George William",
	title="A New Binary Classifier: Clustering-Launched Classification",
	bookTitle="Computational Intelligence: International Conference on Intelligent Computing, ICIC 2006, Kunming, China, August 16-19, 2006. Proceedings, Part II",
	year="2006",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="278--283",
	isbn="978-3-540-37275-2",
	doi="10.1007/11816171_35",
	url="http://dx.doi.org/10.1007/11816171_35"
}

@article{Batista:2004:SBS:1007730.1007735,
	author = {Batista, Gustavo E. A. P. A. and Prati, Ronaldo C. and Monard, Maria Carolina},
	title = {A Study of the Behavior of Several Methods for Balancing Machine Learning Training Data},
	journal = {SIGKDD Explor. Newsl.},
	issue_date = {June 2004},
	volume = {6},
	number = {1},
	month = jun,
	year = {2004},
	issn = {1931-0145},
	pages = {20--29},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/1007730.1007735},
	doi = {10.1145/1007730.1007735},
	acmid = {1007735},
	publisher = {ACM},
	address = {New York, NY, USA},
} 

@ARTICLE{4309452, 
	author={I. Tomek},
	journal={IEEE Transactions on Systems, Man, and Cybernetics}, 
	title={Two Modifications of CNN}, 
	year={1976}, 
	volume={SMC-6}, 
	number={11}, 
	pages={769-772}, 
	keywords={Bibliographies;Cellular neural networks;Computer science;Cybernetics;Fuzzy control;Fuzzy logic;Fuzzy set theory;Fuzzy sets;Minimization methods;Neural networks}, 
	doi={10.1109/TSMC.1976.4309452}, 
	ISSN={0018-9472}, 
	month={Nov},}

@ARTICLE{1056066, 
	author={K. Gowda and G. Krishna}, 
	journal={IEEE Transactions on Information Theory}, 
	title={The condensed nearest neighbor rule using the concept of mutual nearest neighborhood (Corresp.)}, 
	year={1979}, 
	volume={25}, 
	number={4}, 
	pages={488-490}, 
	keywords={Pattern classification;Biological cells;Cellular neural networks;DNA;Extraterrestrial measurements;Humans;Image analysis;Iterative algorithms;Nearest neighbor searches;Neural networks;Testing}, 
	doi={10.1109/TIT.1979.1056066}, 
	ISSN={0018-9448}, 
	month={Jul},}

@INPROCEEDINGS{Kubat97addressingthe,
	author = {Miroslav Kubat and Stan Matwin},
	title = {Addressing the Curse of Imbalanced Training Sets: One-Sided Selection},
	booktitle = {In Proceedings of the Fourteenth International Conference on Machine Learning},
	year = {1997},
	pages = {179--186},
	publisher = {Morgan Kaufmann}
}

@inproceedings{Laurikkala:2001:IID:648155.757340,
	author = {Laurikkala, Jorma},
	title = {Improving Identification of Difficult Small Classes by Balancing Class Distribution},
	booktitle = {Proceedings of the 8th Conference on AI in Medicine in Europe: Artificial Intelligence Medicine},
	series = {AIME '01},
	year = {2001},
	isbn = {3-540-42294-3},
	pages = {63--66},
	numpages = {4},
	url = {http://dl.acm.org/citation.cfm?id=648155.757340},
	acmid = {757340},
	publisher = {Springer-Verlag},
	address = {London, UK, UK},
} 

@inproceedings{mani2003knn,
	title={kNN approach to unbalanced data distributions: a case study involving information extraction},
	author={Zhang, I and Mani, Inderjeet},
	booktitle={Proceedings of workshop on learning from imbalanced datasets},
	year={2003}
}

@article{Smith:2014:ILA:2843614.2843686,
	author = {Smith, Michael R. and Martinez, Tony and Giraud-Carrier, Christophe},
	title = {An Instance Level Analysis of Data Complexity},
	journal = {Mach. Learn.},
	issue_date = {May       2014},
	volume = {95},
	number = {2},
	month = may,
	year = {2014},
	issn = {0885-6125},
	pages = {225--256},
	numpages = {32},
	url = {http://dx.doi.org/10.1007/s10994-013-5422-z},
	doi = {10.1007/s10994-013-5422-z},
	acmid = {2843686},
	publisher = {Kluwer Academic Publishers},
	address = {Hingham, MA, USA},
	keywords = {Data complexity, Dataset hardness, Instance hardness},
} 

@article{Chawla:2002:SSM:1622407.1622416,
	author = {Chawla, Nitesh V. and Bowyer, Kevin W. and Hall, Lawrence O. and Kegelmeyer, W. Philip},
	title = {SMOTE: Synthetic Minority Over-sampling Technique},
	journal = {J. Artif. Int. Res.},
	issue_date = {January 2002},
	volume = {16},
	number = {1},
	month = jun,
	year = {2002},
	issn = {1076-9757},
	pages = {321--357},
	numpages = {37},
	url = {http://dl.acm.org/citation.cfm?id=1622407.1622416},
	acmid = {1622416},
	publisher = {AI Access Foundation},
	address = {USA},
} 

@INPROCEEDINGS{4633969, 
	author={Haibo He and Yang Bai and E. A. Garcia and Shutao Li}, 
	booktitle={2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)}, 
	title={ADASYN: Adaptive synthetic sampling approach for imbalanced learning}, 
	year={2008}, 
	pages={1322-1328}, 
	keywords={learning (artificial intelligence);pattern classification;sampling methods;statistical distributions;adaptive synthetic sampling approach;classification decision boundary;imbalanced data classification;imbalanced data set learning;weighted distribution;Bioinformatics;Boosting;Cancer;Data analysis;Data mining;Decision trees;Helium;Machine learning;Sampling methods;Space technology}, 
	doi={10.1109/IJCNN.2008.4633969}, 
	ISSN={2161-4393}, 
	month={June},}

@inproceedings{batista2003balancing,
	title={Balancing Training Data for Automated Annotation of Keywords: a Case Study.},
	author={Batista, Gustavo EAPA and Bazzan, Ana LC and Monard, Maria Carolina},
	booktitle={WOB},
	pages={10--18},
	year={2003}
}

@article{Chawla:2004:ESI:1007730.1007733,
	author = {Chawla, Nitesh V. and Japkowicz, Nathalie and Kotcz, Aleksander},
	title = {Editorial: Special Issue on Learning from Imbalanced Data Sets},
	journal = {SIGKDD Explor. Newsl.},
	issue_date = {June 2004},
	volume = {6},
	number = {1},
	month = jun,
	year = {2004},
	issn = {1931-0145},
	pages = {1--6},
	numpages = {6},
	url = {http://doi.acm.org/10.1145/1007730.1007733},
	doi = {10.1145/1007730.1007733},
	acmid = {1007733},
	publisher = {ACM},
	address = {New York, NY, USA},
} 

@article {PMID:25988841,
	Title = {Application of high-dimensional feature selection: evaluation for genomic prediction in man},
	Author = {Bermingham, ML and Pong-Wong, R and Spiliopoulou, A and Hayward, C and Rudan, I and Campbell, H and Wright, AF and Wilson, JF and Agakov, F and Navarro, P and Haley, CS},
	DOI = {10.1038/srep10312},
	Volume = {5},
	Year = {2015},
	Journal = {Scientific reports},
	ISSN = {2045-2322},
	Pages = {10312},
	URL = {http://europepmc.org/articles/PMC4437376},
}

@article{Guyon:2003:IVF:944919.944968,
	author = {Guyon, Isabelle and Elisseeff, Andr{\'e}},
	title = {An Introduction to Variable and Feature Selection},
	journal = {J. Mach. Learn. Res.},
	issue_date = {3/1/2003},
	volume = {3},
	month = mar,
	year = {2003},
	issn = {1532-4435},
	pages = {1157--1182},
	numpages = {26},
	url = {http://dl.acm.org/citation.cfm?id=944919.944968},
	acmid = {944968},
	publisher = {JMLR.org},
} 

@inproceedings{mccallum1998comparison,
	title={A comparison of event models for naive bayes text classification},
	author={McCallum, Andrew and Nigam, Kamal and others},
	booktitle={AAAI-98 workshop on learning for text categorization},
	volume={752},
	pages={41--48},
	year={1998}
}

@inproceedings{John:1995:ECD:2074158.2074196,
	author = {John, George H. and Langley, Pat},
	title = {Estimating Continuous Distributions in Bayesian Classifiers},
	booktitle = {Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence},
	series = {UAI'95},
	year = {1995},
	isbn = {1-55860-385-9},
	location = {Montr\&\#233;al, Qu\&\#233;, Canada},
	pages = {338--345},
	numpages = {8},
	url = {http://dl.acm.org/citation.cfm?id=2074158.2074196},
	acmid = {2074196},
	publisher = {Morgan Kaufmann Publishers Inc.},
	address = {San Francisco, CA, USA},
} 

@misc{Lichman:2013 ,
	author = "M. Lichman",
	year = "2013",
	title = "{UCI} Machine Learning Repository",
	url = "http://archive.ics.uci.edu/ml",
	institution = "University of California, Irvine, School of Information and Computer Sciences" } 

@article{scikit-learn,
	title={Scikit-learn: Machine Learning in {P}ython},
	author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
	and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
	and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
	Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
	journal={Journal of Machine Learning Research},
	volume={12},
	pages={2825--2830},
	year={2011}
}

@ARTICLE{7140733,
	author={A. Akusok and K. M. Björk and Y. Miche and A. Lendasse},
	journal={IEEE Access},
	title={High-Performance Extreme Learning Machines: A Complete Toolbox for Big Data Applications},
	year={2015},
	volume={3},
	pages={1011-1025},
	keywords={Learning systems;Machine learning;Performance evaluation},
	doi={10.1109/ACCESS.2015.2450498},
	ISSN={2169-3536},
	month={},}

@article{lemaitre2016imbalanced,
	author    = {Guillaume Lema\^{i}tre and
	Fernando Nogueira and
	Christos K. Aridas},
	title     = {Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning},
	journal   = {CoRR},
	volume    = {abs/1609.06570},
	year      = {2016},
	url       = {http://arxiv.org/abs/1609.06570}
}

@article{Li2006772,
	title = "The evaluation of consumer loans using support vector machines",
	journal = "Expert Systems with Applications",
	volume = "30",
	number = "4",
	pages = "772-782",
	year = "2006",
	note = "",
	issn = "0957-4174",
	doi = "http://dx.doi.org/10.1016/j.eswa.2005.07.041",
	url = "http://www.sciencedirect.com/science/article/pii/S0957417405001739",
	author = "Sheng-Tun Li and Weissor Shiue and Meng-Huah Huang",
	keywords = "Consumer loans",
	keywords = "Support vector machines",
	keywords = "Artificial neural networks",
	keywords = "Credit scoring",
	keywords = "Decision making ",
	abstract = "The commencement of the Basel \{II\} requirement, popularization of consumer loans and the intense competition in financial market has increased the awareness of the critical delinquency issue for financial institutions in granting loans to potential applicants. In the past few decades, the scheme of artificial neural networks has been successfully applied to the financial field. Recently, the Support Vector Machine (SVM) has emerged as the better neural network in dealing with classification and forecasting problems due to its superior features of generalization performance and global optimum. This study develops a loan evaluation model using \{SVM\} to identify potential applicants for consumer loans. In addition to conducting experiments on performance comparison via cross-validation and paired t test, we analyze misclassification errors in terms of Type I and Type \{II\} and their effect on selecting network parameters of SVM. The analysis findings facilitate the development of a useful visual decision-support tool. The experimental results using a real-world data set reveal that \{SVM\} surpasses traditional neural network models in generalization performance and visualization via the visual tool, which helps decision makers determine appropriate loan evaluation strategies. "
}

@inproceedings{lessmanna2013benchmarking,
	title={Benchmarking state-of-the-art classification algorithms for credit scoring: A ten-year update},
	author={Lessmanna, Stefan and Seowb, H and Baesenscd, Bart and Thomasd, Lyn C},
	booktitle={Credit Scoring and Credit Control XIII},
	address={Edinburgh, UK},
	year={2013}
}

@article{Huang2004543,
	title = "Credit rating analysis with support vector machines and neural networks: a market comparative study",
	journal = "Decision Support Systems",
	volume = "37",
	number = "4",
	pages = "543-558",
	year = "2004",
	note = "Data mining for financial decision making ",
	issn = "0167-9236",
	doi = "http://dx.doi.org/10.1016/S0167-9236(03)00086-1",
	url = "http://www.sciencedirect.com/science/article/pii/S0167923603000861",
	author = "Zan Huang and Hsinchun Chen and Chia-Jung Hsu and Wun-Hwa Chen and Soushan Wu",
	keywords = "Data mining",
	keywords = "Credit rating analysis",
	keywords = "Bond rating prediction",
	keywords = "Backpropagation neural networks",
	keywords = "Support vector machines",
	keywords = "Input variable contribution analysis",
	keywords = "Cross-market analysis ",
	abstract = "Corporate credit rating analysis has attracted lots of research interests in the literature. Recent studies have shown that Artificial Intelligence (AI) methods achieved better performance than traditional statistical methods. This article introduces a relatively new machine learning technique, support vector machines (SVM), to the problem in attempt to provide a model with better explanatory power. We used backpropagation neural network (BNN) as a benchmark and obtained prediction accuracy around 80% for both \{BNN\} and \{SVM\} methods for the United States and Taiwan markets. However, only slight improvement of \{SVM\} was observed. Another direction of the research is to improve the interpretability of the AI-based models. We applied recent research results in neural network model interpretation and obtained relative importance of the input financial variables from the neural network models. Based on these results, we conducted a market comparative analysis on the differences of determining factors in the United States and Taiwan markets. "
}

@article{Huang2007847,
	title = "Credit scoring with a data mining approach based on support vector machines",
	journal = "Expert Systems with Applications",
	volume = "33",
	number = "4",
	pages = "847-856",
	year = "2007",
	note = "",
	issn = "0957-4174",
	doi = "http://dx.doi.org/10.1016/j.eswa.2006.07.007",
	url = "http://www.sciencedirect.com/science/article/pii/S095741740600217X",
	author = "Cheng-Lung Huang and Mu-Chen Chen and Chieh-Jen Wang",
	keywords = "Credit scoring",
	keywords = "Support vector machine",
	keywords = "Genetic programming",
	keywords = "Neural networks",
	keywords = "Decision tree",
	keywords = "Data mining",
	keywords = "Classification ",
	abstract = "The credit card industry has been growing rapidly recently, and thus huge numbers of consumersâ€™ credit data are collected by the credit department of the bank. The credit scoring manager often evaluates the consumerâ€™s credit with intuitive experience. However, with the support of the credit classification model, the manager can accurately evaluate the applicantâ€™s credit score. Support Vector Machine (SVM) classification is currently an active research area and successfully solves classification problems in many domains. This study used three strategies to construct the hybrid SVM-based credit scoring models to evaluate the applicantâ€™s credit score from the applicantâ€™s input features. Two credit datasets in \{UCI\} database are selected as the experimental data to demonstrate the accuracy of the \{SVM\} classifier. Compared with neural networks, genetic programming, and decision tree classifiers, the \{SVM\} classifier achieved an identical classificatory accuracy with relatively few input features. Additionally, combining genetic algorithms with \{SVM\} classifier, the proposed hybrid GA-SVM strategy can simultaneously perform feature selection task and model parameters optimization. Experimental results show that \{SVM\} is a promising addition to the existing data mining methods. "
}

@article{Desai199624,
	title = "A comparison of neural networks and linear scoring models in the credit union environment",
	journal = "European Journal of Operational Research",
	volume = "95",
	number = "1",
	pages = "24-37",
	year = "1996",
	note = "",
	issn = "0377-2217",
	doi = "http://dx.doi.org/10.1016/0377-2217(95)00246-4",
	url = "http://www.sciencedirect.com/science/article/pii/0377221795002464",
	author = "Vijay S. Desai and Jonathan N. Crook and George A. Overstreet Jr.",
	keywords = "Neural networks",
	keywords = "Bamking",
	keywords = "Credit scoring ",
	abstract = "The purpose of the present paper is to explore the ability of neural networks such as multilayer perceptrons and modular neural networks, and traditional techniques such as linear discriminant analysis and logistic regression, in building credit scoring models in the credit union environment. Also, since funding and small sample size often preclude the use of customized credit scoring models at small credit unions, we investigate the performance of generic models and compare them with customized models. Our results indicate that customized neural networks offer a very promising avenue if the measure of performance is percentage of bad loans correctly classified. However, if the measure of performance is percentage of good and bad loans correctly classified, logistic regression models are comparable to the neural networks approach. The performance of generic models was not as good as the customized models, particularly when it came to correctly classifying bad loans. Although we found significant differences in the results for the three credit unions, our modular neural network could not accommodate these differences, indicating that more innovative architectures might be necessary for building effective generic models. "
}

@article{Lee2002245,
	title = "Credit scoring using the hybrid neural discriminant technique",
	journal = "Expert Systems with Applications",
	volume = "23",
	number = "3",
	pages = "245-254",
	year = "2002",
	note = "",
	issn = "0957-4174",
	doi = "http://dx.doi.org/10.1016/S0957-4174(02)00044-1",
	url = "http://www.sciencedirect.com/science/article/pii/S0957417402000441",
	author = "Tian-Shyug Lee and Chih-Chou Chiu and Chi-Jie Lu and I-Fei Chen",
	keywords = "Credit scoring",
	keywords = "Discriminant analysis",
	keywords = "Neural networks",
	keywords = "Model basis ",
	abstract = "Credit scoring has become a very important task as the credit industry has been experiencing double-digit growth rate during the past few decades. The artificial neural network is becoming a very popular alternative in credit scoring models due to its associated memory characteristic and generalization capability. However, the decision of network's topology, importance of potential input variables and the long training process has often long been criticized and hence limited its application in handling credit scoring problems. The objective of the proposed study is to explore the performance of credit scoring by integrating the backpropagation neural networks with traditional discriminant analysis approach. To demonstrate the inclusion of the credit scoring result from discriminant analysis would simplify the network structure and improve the credit scoring accuracy of the designed neural network model, credit scoring tasks are performed on one bank credit card data set. As the results reveal, the proposed hybrid approach converges much faster than the conventional neural networks model. Moreover, the credit scoring accuracies increase in terms of the proposed methodology and outperform traditional discriminant analysis and logistic regression approaches. "
}

@article{Malhotra200383,
	title = "Evaluating consumer loans using neural networks",
	journal = "Omega",
	volume = "31",
	number = "2",
	pages = "83-96",
	year = "2003",
	note = "",
	issn = "0305-0483",
	doi = "http://dx.doi.org/10.1016/S0305-0483(03)00016-1",
	url = "http://www.sciencedirect.com/science/article/pii/S0305048303000161",
	author = "Rashmi Malhotra and D.K Malhotra",
	keywords = "Neural networks",
	keywords = "Credit risk",
	keywords = "Credit unions ",
	abstract = "A number of credit-scoring models that accurately classify consumer loan applications have been developed to aid traditional judgmental methods. This study compares the performance of multiple discriminant analysis (MDA) and neural networks in identifying potential loan. The neural network models consistently perform better than the \{MDA\} models in identifying potential problem loans. To alleviate the problem of bias in the training set and to examine the robustness of neural network classifiers in identifying problem loans, we cross-validate our results through seven different samples of the data. "
}

@article{Angelini2008733,
	title = "A neural network approach for credit risk evaluation",
	journal = "The Quarterly Review of Economics and Finance",
	volume = "48",
	number = "4",
	pages = "733-755",
	year = "2008",
	note = "",
	issn = "1062-9769",
	doi = "http://dx.doi.org/10.1016/j.qref.2007.04.001",
	url = "http://www.sciencedirect.com/science/article/pii/S1062976907000762",
	author = "Eliana Angelini and Giacomo di Tollo and Andrea Roli",
	keywords = "Credit risk",
	keywords = "Basel II",
	keywords = "Neural networks ",
	abstract = "The Basel Committee on Banking Supervision proposes a capital adequacy framework that allows banks to calculate capital requirement for their banking books using internal assessments of key risk drivers. Hence the need for systems to assess credit risk. Among the new methods, artificial neural networks have shown promising results. In this work, we describe the case of a successful application of neural networks to credit risk assessment. We developed two neural network systems, one with a standard feedforward network, while the other with a special purpose architecture. The application is tested on real-world data, related to Italian small businesses. We show that neural networks can be very successful in learning and estimating the in bonis/default tendency of a borrower, provided that careful data analysis, data pre-processing and training are performed. "
}

@article{Bekhet201420,
	title = "Credit risk assessment model for Jordanian commercial banks: Neural scoring approach",
	journal = "Review of Development Finance",
	volume = "4",
	number = "1",
	pages = "20-28",
	year = "2014",
	note = "",
	issn = "1879-9337",
	doi = "http://dx.doi.org/10.1016/j.rdf.2014.03.002",
	url = "http://www.sciencedirect.com/science/article/pii/S1879933714000050",
	author = "Hussain Ali Bekhet and Shorouq Fathi Kamel Eletter",
	keywords = "Artificial neural network",
	keywords = "Credit scoring",
	keywords = "Logistic regression",
	keywords = "Credit risk",
	keywords = "Commercial bank",
	keywords = "Jordan ",
	abstract = "Abstract Despite the increase in the number of non-performing loans and competition in the banking market, most of the Jordanian commercial banks are reluctant to use data mining tools to support credit decisions. Artificial neural networks represent a new family of statistical techniques and promising data mining tools that have been used successfully in classification problems in many domains. This paper proposes two credit scoring models using data mining techniques to support loan decisions for the Jordanian commercial banks. Loan application evaluation would improve credit decision effectiveness and control loan office tasks, as well as save analysis time and cost. Both accepted and rejected loan applications, from different Jordanian commercial banks, were used to build the credit scoring models. The results indicate that the logistic regression model performed slightly better than the radial basis function model in terms of the overall accuracy rate. However, the radial basis function was superior in identifying those customers who may default. "
}

@article{Abdou2016,
	title = "Predicting creditworthiness in retail banking with limited scoring data",
	journal = "Knowledge-Based Systems",
	year = "2016",
	note = "",
	issn = "0950-7051",
	doi = "http://dx.doi.org/10.1016/j.knosys.2016.03.023",
	url = "http://www.sciencedirect.com/science/article/pii/S0950705116300156",
	author = "Hussein A. Abdou and Marc D. Dongmo Tsafack and Collins G. Ntim and Rose D. Baker",
	keywords = "Predicting creditworthiness",
	keywords = "credit scoring",
	keywords = "cascade correlation neural networks",
	keywords = "CART",
	keywords = "limited data ",
	abstract = "Abstract The preoccupation with modelling credit scoring systems including their relevance to predicting and decision making in the financial sector has been with developed countries, whilst developing countries have been largely neglected. The focus of our investigation is on the Cameroonian banking sector with implications for fellow members of the Banque des Etats de L'Afrique Centrale (BEAC) family which apply the same system. We apply logistic regression (LR), Classification and Regression Tree (CART) and Cascade Correlation Neural Network (CCNN) in building our knowledge-based scoring models. To compare various modelsâ€™ performances we use \{ROC\} curves and Gini coefficients as evaluation criteria and the Kolmogorov-Smirnov curve as a robustness test. The results demonstrate that an improvement in terms of predicting power from 15.69% default cases under the current system, to 7.68% based on the best scoring model, namely \{CCNN\} can be achieved. The predictive capabilities of all models are rated as at least very good using the Gini coefficient; and rated excellent using the \{ROC\} curve for CCNN. Our robustness test confirmed these results. It should be emphasised that in terms of prediction rate, \{CCNN\} is superior to the other techniques investigated in this paper. Also, a sensitivity analysis of the variables identifies previous occupation, borrower's account functioning, guarantees, other loans and monthly expenses as key variables in the forecasting and decision making processes which are at the heart of overall credit policy. "
}

@article{Twala20103326,
	title = "Multiple classifier application to credit risk assessment",
	journal = "Expert Systems with Applications",
	volume = "37",
	number = "4",
	pages = "3326-3336",
	year = "2010",
	note = "",
	issn = "0957-4174",
	doi = "http://dx.doi.org/10.1016/j.eswa.2009.10.018",
	url = "http://www.sciencedirect.com/science/article/pii/S0957417409008847",
	author = "Bhekisipho Twala",
	keywords = "Machine learning",
	keywords = "Supervised learning",
	keywords = "Statistical pattern recognition",
	keywords = "Ensemble",
	keywords = "Credit risk prediction",
	keywords = "Noise ",
	abstract = "Credit risk prediction models seek to predict quality factors such as whether an individual will default (bad applicant) on a loan or not (good applicant). This can be treated as a kind of machine learning (ML) problem. Recently, the use of \{ML\} algorithms has proven to be of great practical value in solving a variety of risk problems including credit risk prediction. One of the most active areas of recent research in \{ML\} has been the use of ensemble (combining) classifiers. Research indicates that ensemble individual classifiers lead to a significant improvement in classification performance by having them vote for the most popular class. This paper explores the predicted behaviour of five classifiers for different types of noise in terms of credit risk prediction accuracy, and how such accuracy could be improved by using classifier ensembles. Benchmarking results on four credit datasets and comparison with the performance of each individual classifier on predictive accuracy at various attribute noise levels are presented. The experimental evaluation shows that the ensemble of classifiers technique has the potential to improve prediction accuracy. "
}

@article{Wang2011223,
	title = "A comparative assessment of ensemble learning for credit scoring",
	journal = "Expert Systems with Applications",
	volume = "38",
	number = "1",
	pages = "223-230",
	year = "2011",
	note = "",
	issn = "0957-4174",
	doi = "http://dx.doi.org/10.1016/j.eswa.2010.06.048",
	url = "http://www.sciencedirect.com/science/article/pii/S095741741000552X",
	author = "Gang Wang and Jinxing Hao and Jian Ma and Hongbing Jiang",
	keywords = "Credit scoring",
	keywords = "Ensemble learning",
	keywords = "Bagging",
	keywords = "Boosting",
	keywords = "Stacking ",
	abstract = "Both statistical techniques and Artificial Intelligence (AI) techniques have been explored for credit scoring, an important finance activity. Although there are no consistent conclusions on which ones are better, recent studies suggest combining multiple classifiers, i.e., ensemble learning, may have a better performance. In this study, we conduct a comparative assessment of the performance of three popular ensemble methods, i.e., Bagging, Boosting, and Stacking, based on four base learners, i.e., Logistic Regression Analysis (LRA), Decision Tree (DT), Artificial Neural Network (ANN) and Support Vector Machine (SVM). Experimental results reveal that the three ensemble methods can substantially improve individual base learners. In particular, Bagging performs better than Boosting across all credit datasets. Stacking and Bagging \{DT\} in our experiments, get the best performance in terms of average accuracy, type I error and type \{II\} error. "
}

@article{Tsai20082639,
	title = "Using neural network ensembles for bankruptcy prediction and credit scoring",
	journal = "Expert Systems with Applications",
	volume = "34",
	number = "4",
	pages = "2639-2649",
	year = "2008",
	note = "",
	issn = "0957-4174",
	doi = "http://dx.doi.org/10.1016/j.eswa.2007.05.019",
	url = "http://www.sciencedirect.com/science/article/pii/S0957417407001558",
	author = "Chih-Fong Tsai and Jhen-Wei Wu",
	keywords = "Bankruptcy prediction",
	keywords = "Credit scoring",
	keywords = "Neural networks",
	keywords = "Classifier ensembles ",
	abstract = "Bankruptcy prediction and credit scoring have long been regarded as critical topics and have been studied extensively in the accounting and finance literature. Artificial intelligence and machine learning techniques have been used to solve these financial decision-making problems. The multilayer perceptron (MLP) network trained by the back-propagation learning algorithm is the mostly used technique for financial decision-making problems. In addition, it is usually superior to other traditional statistical models. Recent studies suggest combining multiple classifiers (or classifier ensembles) should be better than single classifiers. However, the performance of multiple classifiers in bankruptcy prediction and credit scoring is not fully understood. In this paper, we investigate the performance of a single classifier as the baseline classifier to compare with multiple classifiers and diversified multiple classifiers by using neural networks based on three datasets. By comparing with the single classifier as the benchmark in terms of average prediction accuracy, the multiple classifiers only perform better in one of the three datasets. The diversified multiple classifiers trained by not only different classifier parameters but also different sets of training data perform worse in all datasets. However, for the Type I and Type \{II\} errors, there is no exact winner. We suggest that it is better to consider these three classifier architectures to make the optimal financial decision. "
}

@article{Hsieh2010534,
	title = "A data driven ensemble classifier for credit scoring analysis",
	journal = "Expert Systems with Applications",
	volume = "37",
	number = "1",
	pages = "534-545",
	year = "2010",
	note = "",
	issn = "0957-4174",
	doi = "http://dx.doi.org/10.1016/j.eswa.2009.05.059",
	url = "http://www.sciencedirect.com/science/article/pii/S0957417407001558",
	author = "Nan-Chen Hsieh and Lun-Ping Hung",
	keywords = "Clustering",
	keywords = "Ensemble classifier",
	keywords = "Neural network",
	keywords = "Bayesian network",
	keywords = "Class-wise classification",
	keywords = "Credit scoring system ",
	abstract = "This study focuses on predicting whether a credit applicant can be categorized as good, bad or borderline from information initially supplied. This is essentially a classification task for credit scoring. Given its importance, many researchers have recently worked on an ensemble of classifiers. However, to the best of our knowledge, unrepresentative samples drastically reduce the accuracy of the deployment classifier. Few have attempted to preprocess the input samples into more homogeneous cluster groups and then fit the ensemble classifier accordingly. For this reason, we introduce the concept of class-wise classification as a preprocessing step in order to obtain an efficient ensemble classifier. This strategy would work better than a direct ensemble of classifiers without the preprocessing step. The proposed ensemble classifier is constructed by incorporating several data mining techniques, mainly involving optimal associate binning to discretize continuous values; neural network, support vector machine, and Bayesian network are used to augment the ensemble classifier. In particular, the Markov blanket concept of Bayesian network allows for a natural form of feature selection, which provides a basis for mining association rules. The learned knowledge is represented in multiple forms, including causal diagram and constrained association rules. The data driven nature of the proposed system distinguishes it from existing hybrid/ensemble credit scoring systems. "
}

@article{Nanni20093028,
	title = "An experimental comparison of ensemble of classifiers for bankruptcy prediction and credit scoring",
	journal = "Expert Systems with Applications",
	volume = "36",
	number = "2, Part 2",
	pages = "3028-3033",
	year = "2009",
	note = "",
	issn = "0957-4174",
	doi = "http://dx.doi.org/10.1016/j.eswa.2008.01.018",
	url = "http://www.sciencedirect.com/science/article/pii/S0957417408000249",
	author = "Loris Nanni and Alessandra Lumini",
	keywords = "Bankruptcy prediction",
	keywords = "Credit scoring",
	keywords = "Ensemble of classifiers ",
	abstract = "In this paper, we investigate the performance of several systems based on ensemble of classifiers for bankruptcy prediction and credit scoring. The obtained results are very encouraging, our results improved the performance obtained using the stand-alone classifiers. We show that the method â€œRandom Subspaceâ€ outperforms the other ensemble methods tested in this paper. Moreover, the best stand-alone method is the multi-layer perceptron neural net, while the best method tested in this work is the Random Subspace of Levenbergâ€“Marquardt neural net. In this work, three financial datasets are chosen for the experiments: Australian credit, German credit, and Japanese credit. "
}

@article{Dreiseitl2002352,
	title = "Logistic regression and artificial neural network classification models: a methodology review ",
	journal = "Journal of Biomedical Informatics ",
	volume = "35",
	number = "5–6",
	pages = "352 - 359",
	year = "2002",
	note = "",
	issn = "1532-0464",
	doi = "http://dx.doi.org/10.1016/S1532-0464(03)00034-0",
	url = "http://www.sciencedirect.com/science/article/pii/S1532046403000340",
	author = "Stephan Dreiseitl and Lucila Ohno-Machado",
	keywords = "Artificial neural networks",
	keywords = "Logistic regression",
	keywords = "Classification",
	keywords = "Model comparison",
	keywords = "Model evaluation",
	keywords = "Medical data analysis ",
	abstract = "Logistic regression and artificial neural networks are the models of choice in many medical data classification tasks. In this review, we summarize the differences and similarities of these models from a technical point of view, and compare them with other machine learning algorithms. We provide considerations useful for critically assessing the quality of the models and the results based on these models. Finally, we summarize our findings on how quality criteria for logistic regression and artificial neural network models are met in a sample of papers from the medical literature. "
}

@article{steyerberg2010assessing,
	title={Assessing the performance of prediction models: a framework for some traditional and novel measures},
	author={Steyerberg, Ewout W and Vickers, Andrew J and Cook, Nancy R and Gerds, Thomas and Gonen, Mithat and Obuchowski, Nancy and Pencina, Michael J and Kattan, Michael W},
	journal={Epidemiology (Cambridge, Mass.)},
	volume={21},
	number={1},
	pages={128-138},
	year={2010},
	publisher={NIH Public Access}
}

@article{Hand2013492,
	title = "When is the area under the receiver operating characteristic curve an appropriate measure of classifier performance? ",
	journal = "Pattern Recognition Letters ",
	volume = "34",
	number = "5",
	pages = "492 - 495",
	year = "2013",
	note = "",
	issn = "0167-8655",
	doi = "http://dx.doi.org/10.1016/j.patrec.2012.12.004",
	url = "http://www.sciencedirect.com/science/article/pii/S0167865512003923",
	author = "D.J. Hand and C. Anagnostopoulos",
	keywords = "Area under the curve",
	keywords = "Classification",
	keywords = "Gini coefficient",
	keywords = "ROC curve",
	keywords = "Screening ",
	abstract = "The area under the receiver operating characteristic curve is a widely used measure of the performance of classification rules. This paper shows that when classifications are based solely on data describing individual objects to be classified, the area under the receiver operating characteristic curve is an incoherent measure of performance, in the sense that the measure itself depends on the classifier being measured. It significantly extends earlier work by showing that this incoherence is not a consequence of a cost-based interpretation of misclassifications, but is a fundamental property of the area under the curve itself. The paper also shows that if additional information, such as the class assignments of other objects, is taken into account when making a classification, then the area under the curve is a coherent measure, although in those circumstances it makes an assumption which is seldom if ever appropriate. "
}

@article{Demsar:2006:SCC:1248547.1248548,
	author = {Dem\v{s}ar, Janez},
	title = {Statistical Comparisons of Classifiers over Multiple Data Sets},
	journal = {J. Mach. Learn. Res.},
	issue_date = {12/1/2006},
	volume = {7},
	month = dec,
	year = {2006},
	issn = {1532-4435},
	pages = {1--30},
	numpages = {30},
	url = {http://dl.acm.org/citation.cfm?id=1248547.1248548},
	acmid = {1248548},
	publisher = {JMLR.org},
} 

@article{garcia2008extension,
	title={An Extension on “Statistical Comparisons of Classifiers over Multiple Data Sets” for all Pairwise Comparisons},
	author={Garc{\i}a, Salvador and Herrera, Francisco},
	journal={Journal of Machine Learning Research},
	volume={9},
	pages={2677--2694},
	year={2008}
}

 @Manual{pmcmr,
	title = {The Pairwise Multiple Comparison of Mean Ranks Package
	(PMCMR)},
	author = {Thorsten Pohlert},
	year = {2014},
	note = {R package},
	url = {http://CRAN.R-project.org/package=PMCMR},
}

@article{Hand:2009:MCP:1612990.1613009,
	author = {Hand, David J.},
	title = {Measuring Classifier Performance: A Coherent Alternative to the Area Under the ROC Curve},
	journal = {Mach. Learn.},
	issue_date = {October   2009},
	volume = {77},
	number = {1},
	month = oct,
	year = {2009},
	issn = {0885-6125},
	pages = {103--123},
	numpages = {21},
	url = {http://dx.doi.org/10.1007/s10994-009-5119-5},
	doi = {10.1007/s10994-009-5119-5},
	acmid = {1613009},
	publisher = {Kluwer Academic Publishers},
	address = {Hingham, MA, USA},
	keywords = {AUC, Classification, Cost, Error rate, Loss, Misclassification rate, ROC curves, Sensitivity, Specificity},
} 






